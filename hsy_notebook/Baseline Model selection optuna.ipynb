{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumetable(df):\n",
    "    print(f'Dataset shape: {df.shape}')\n",
    "    summary = pd.Frame(df.dtypes, columns=[' Type'])\n",
    "    summary = summary.reset_index()\n",
    "    summary = summary.rename(columns={'index': 'Feature'})\n",
    "    summary['Missing Values Count'] = df.isnull().sum().values\n",
    "    summary['Missing Values Percentage'] = df.isnull().sum().values / len(df) * 100\n",
    "    summary['Unique Values Count'] = df.nunique().values\n",
    "    summary['First Value'] = df.iloc[0].values\n",
    "    summary['Second Value'] = df.iloc[1].values\n",
    "    summary['Third Value'] = df.iloc[2].values\n",
    "    summary['Second to Last Value'] = df.iloc[-2].values\n",
    "    summary['Last Value'] = df.iloc[-1].values\n",
    "    return summary\n",
    "\n",
    "def seed_everything(seed = 9234):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    # torch.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed(seed)\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    # torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Data/Soo_T_PATIENTS_DAILY_WHOLE_0812.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (26010, 59)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Missing Values Count</th>\n",
       "      <th>Missing Values Percentage</th>\n",
       "      <th>Unique Values Count</th>\n",
       "      <th>First Value</th>\n",
       "      <th>Second Value</th>\n",
       "      <th>Third Value</th>\n",
       "      <th>Second to Last Value</th>\n",
       "      <th>Last Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sido</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>경기도</td>\n",
       "      <td>충청북도</td>\n",
       "      <td>대구광역시</td>\n",
       "      <td>경상남도</td>\n",
       "      <td>인천광역시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>create_date</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1530</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>2023-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sido_cd</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weekend_yn</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grid_x</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>89</td>\n",
       "      <td>91</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>grid_y</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>120</td>\n",
       "      <td>107</td>\n",
       "      <td>90</td>\n",
       "      <td>77</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sat_x</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sat_y</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>min_ta</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253</td>\n",
       "      <td>9.6</td>\n",
       "      <td>10.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>18.3</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_ta</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>259</td>\n",
       "      <td>24.2</td>\n",
       "      <td>23.7</td>\n",
       "      <td>25.3</td>\n",
       "      <td>25.5</td>\n",
       "      <td>23.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mean_ta</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231</td>\n",
       "      <td>16.6</td>\n",
       "      <td>17.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gap_ta</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>194</td>\n",
       "      <td>14.6</td>\n",
       "      <td>13.2</td>\n",
       "      <td>11.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>min_tafeel</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2144</td>\n",
       "      <td>12.35</td>\n",
       "      <td>12.78</td>\n",
       "      <td>16.29</td>\n",
       "      <td>20.86</td>\n",
       "      <td>20.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max_tafeel</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1943</td>\n",
       "      <td>22.04</td>\n",
       "      <td>22.16</td>\n",
       "      <td>23.66</td>\n",
       "      <td>25.05</td>\n",
       "      <td>25.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mean_tafeel</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>19.6</td>\n",
       "      <td>23.1</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gap_tafeel</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142</td>\n",
       "      <td>9.7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>min_hm</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max_hm</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73</td>\n",
       "      <td>98.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mean_hm</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>739</td>\n",
       "      <td>61.1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>64.7</td>\n",
       "      <td>76.7</td>\n",
       "      <td>75.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gap_hm</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>min_wbtemp</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246</td>\n",
       "      <td>8.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>12.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>max_wbtemp</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234</td>\n",
       "      <td>14.2</td>\n",
       "      <td>14.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mean_wbtemp</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229</td>\n",
       "      <td>11.6</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>18.4</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gap_wbtemp</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>min_ws</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>max_ws</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mean_ws</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tropical_3days</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>heatwave_temp</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>heatalert_temp</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ta_min_3days</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243</td>\n",
       "      <td>9.6</td>\n",
       "      <td>10.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>18.3</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ta_max_3days</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246</td>\n",
       "      <td>24.2</td>\n",
       "      <td>23.7</td>\n",
       "      <td>25.3</td>\n",
       "      <td>30.8</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>gap_ta_minmax</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>213</td>\n",
       "      <td>14.6</td>\n",
       "      <td>13.2</td>\n",
       "      <td>11.8</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>popular_man</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170</td>\n",
       "      <td>6219813</td>\n",
       "      <td>796141</td>\n",
       "      <td>1241119</td>\n",
       "      <td>1636987</td>\n",
       "      <td>1499016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>popular_woman</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170</td>\n",
       "      <td>6138017</td>\n",
       "      <td>782792</td>\n",
       "      <td>1252145</td>\n",
       "      <td>1614171</td>\n",
       "      <td>1498394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>agriculture_man</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169</td>\n",
       "      <td>186278</td>\n",
       "      <td>92687</td>\n",
       "      <td>25045</td>\n",
       "      <td>114000</td>\n",
       "      <td>11835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>agriculture_woman</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169</td>\n",
       "      <td>188594</td>\n",
       "      <td>95065</td>\n",
       "      <td>24142</td>\n",
       "      <td>121775</td>\n",
       "      <td>12309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ta_min_am</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ta_max_am</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ta_mean_am</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ta_min_pm</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ta_max_pm</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ta_mean_pm</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ta_min_six_am1</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ta_max_six_am1</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ta_mean_six_am1</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ta_min_six_am2</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ta_max_six_am2</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ta_mean_six_am2</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ta_min_six_pm1</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ta_max_six_pm1</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ta_mean_six_pm1</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ta_min_six_pm2</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ta_max_six_pm2</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ta_mean_six_pm2</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>patientsCnt</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>jenks_cluster</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>instDate</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>2024-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>updtDate</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>2024-07-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature Data Type  Missing Values Count  \\\n",
       "0                sido    object                     0   \n",
       "1         create_date    object                     0   \n",
       "2             sido_cd     int64                     0   \n",
       "3          weekend_yn     int64                     0   \n",
       "4              grid_x     int64                     0   \n",
       "5              grid_y     int64                     0   \n",
       "6               sat_x   float64                     0   \n",
       "7               sat_y   float64                     0   \n",
       "8              min_ta   float64                     0   \n",
       "9              max_ta   float64                     0   \n",
       "10            mean_ta   float64                     0   \n",
       "11             gap_ta   float64                     0   \n",
       "12         min_tafeel   float64                     0   \n",
       "13         max_tafeel   float64                     0   \n",
       "14        mean_tafeel   float64                     0   \n",
       "15         gap_tafeel   float64                     0   \n",
       "16             min_hm   float64                     0   \n",
       "17             max_hm   float64                     0   \n",
       "18            mean_hm   float64                     0   \n",
       "19             gap_hm   float64                     0   \n",
       "20         min_wbtemp   float64                     0   \n",
       "21         max_wbtemp   float64                     0   \n",
       "22        mean_wbtemp   float64                     0   \n",
       "23         gap_wbtemp   float64                     0   \n",
       "24             min_ws   float64                     0   \n",
       "25             max_ws   float64                     0   \n",
       "26            mean_ws   float64                     0   \n",
       "27     tropical_3days     int64                     0   \n",
       "28      heatwave_temp     int64                     0   \n",
       "29     heatalert_temp     int64                     0   \n",
       "30       ta_min_3days   float64                     0   \n",
       "31       ta_max_3days   float64                     0   \n",
       "32      gap_ta_minmax   float64                     0   \n",
       "33        popular_man     int64                     0   \n",
       "34      popular_woman     int64                     0   \n",
       "35    agriculture_man     int64                     0   \n",
       "36  agriculture_woman     int64                     0   \n",
       "37          ta_min_am     int64                     0   \n",
       "38          ta_max_am     int64                     0   \n",
       "39         ta_mean_am     int64                     0   \n",
       "40          ta_min_pm     int64                     0   \n",
       "41          ta_max_pm     int64                     0   \n",
       "42         ta_mean_pm     int64                     0   \n",
       "43     ta_min_six_am1   float64                     0   \n",
       "44     ta_max_six_am1   float64                     0   \n",
       "45    ta_mean_six_am1   float64                     0   \n",
       "46     ta_min_six_am2     int64                     0   \n",
       "47     ta_max_six_am2     int64                     0   \n",
       "48    ta_mean_six_am2     int64                     0   \n",
       "49     ta_min_six_pm1     int64                     0   \n",
       "50     ta_max_six_pm1     int64                     0   \n",
       "51    ta_mean_six_pm1     int64                     0   \n",
       "52     ta_min_six_pm2     int64                     0   \n",
       "53     ta_max_six_pm2     int64                     0   \n",
       "54    ta_mean_six_pm2     int64                     0   \n",
       "55        patientsCnt     int64                     0   \n",
       "56      jenks_cluster     int64                     0   \n",
       "57           instDate    object                     0   \n",
       "58           updtDate    object                     0   \n",
       "\n",
       "    Missing Values Percentage  Unique Values Count First Value Second Value  \\\n",
       "0                         0.0                   17         경기도         충청북도   \n",
       "1                         0.0                 1530  2014-05-01   2014-05-01   \n",
       "2                         0.0                   17          31           33   \n",
       "3                         0.0                    2           0            0   \n",
       "4                         0.0                   15          60           69   \n",
       "5                         0.0                   16         120          107   \n",
       "6                         0.0                    1         0.0          0.0   \n",
       "7                         0.0                    1         0.0          0.0   \n",
       "8                         0.0                  253         9.6         10.5   \n",
       "9                         0.0                  259        24.2         23.7   \n",
       "10                        0.0                  231        16.6         17.1   \n",
       "11                        0.0                  194        14.6         13.2   \n",
       "12                        0.0                 2144       12.35        12.78   \n",
       "13                        0.0                 1943       22.04        22.16   \n",
       "14                        0.0                  223        17.0         17.5   \n",
       "15                        0.0                  142         9.7          9.4   \n",
       "16                        0.0                   97        30.0         33.0   \n",
       "17                        0.0                   73        98.0         91.0   \n",
       "18                        0.0                  739        61.1         60.0   \n",
       "19                        0.0                  120         5.4          5.6   \n",
       "20                        0.0                  246         8.8          9.3   \n",
       "21                        0.0                  234        14.2         14.9   \n",
       "22                        0.0                  229        11.6         12.0   \n",
       "23                        0.0                  120         5.4          5.6   \n",
       "24                        0.0                   76         0.3          0.0   \n",
       "25                        0.0                   91         3.5          3.7   \n",
       "26                        0.0                   96         1.7          1.6   \n",
       "27                        0.0                    4           0            0   \n",
       "28                        0.0                   49           0            0   \n",
       "29                        0.0                   37           0            0   \n",
       "30                        0.0                  243         9.6         10.5   \n",
       "31                        0.0                  246        24.2         23.7   \n",
       "32                        0.0                  213        14.6         13.2   \n",
       "33                        0.0                  170     6219813       796141   \n",
       "34                        0.0                  170     6138017       782792   \n",
       "35                        0.0                  169      186278        92687   \n",
       "36                        0.0                  169      188594        95065   \n",
       "37                        0.0                   28           9           10   \n",
       "38                        0.0                   30          21           21   \n",
       "39                        0.0                   25          13           14   \n",
       "40                        0.0                   27          14           15   \n",
       "41                        0.0                   30          24           23   \n",
       "42                        0.0                   28          20           20   \n",
       "43                        0.0                   29         9.0         10.0   \n",
       "44                        0.0                   27        13.0         14.0   \n",
       "45                        0.0                   27        10.0         12.0   \n",
       "46                        0.0                   28           9           10   \n",
       "47                        0.0                   30          21           21   \n",
       "48                        0.0                   26          15           15   \n",
       "49                        0.0                   29          21           21   \n",
       "50                        0.0                   30          24           23   \n",
       "51                        0.0                   29          22           22   \n",
       "52                        0.0                   27          14           15   \n",
       "53                        0.0                   30          21           22   \n",
       "54                        0.0                   28          17           18   \n",
       "55                        0.0                   42           0            0   \n",
       "56                        0.0                    3           0            0   \n",
       "57                        0.0                    1  2024-07-31   2024-07-31   \n",
       "58                        0.0                    1  2024-07-31   2024-07-31   \n",
       "\n",
       "   Third Value Second to Last Value  Last Value  \n",
       "0        대구광역시                 경상남도       인천광역시  \n",
       "1   2014-05-01           2023-09-30  2023-09-30  \n",
       "2           22                   38          23  \n",
       "3            0                    1           1  \n",
       "4           89                   91          55  \n",
       "5           90                   77         124  \n",
       "6          0.0                  0.0         0.0  \n",
       "7          0.0                  0.0         0.0  \n",
       "8         13.5                 18.3        18.9  \n",
       "9         25.3                 25.5        23.3  \n",
       "10        19.0                 21.5        21.5  \n",
       "11        11.8                  7.2         4.4  \n",
       "12       16.29                20.86       20.11  \n",
       "13       23.66                25.05       25.09  \n",
       "14        19.6                 23.1        23.0  \n",
       "15         7.4                  4.2         5.0  \n",
       "16        27.0                 49.0        62.0  \n",
       "17        97.0                 94.0        84.0  \n",
       "18        64.7                 76.7        75.3  \n",
       "19         3.4                  4.7         5.1  \n",
       "20        12.7                 15.9        15.3  \n",
       "21        16.1                 20.6        20.4  \n",
       "22        14.2                 18.4        18.3  \n",
       "23         3.4                  4.7         5.1  \n",
       "24         0.1                  0.0         0.2  \n",
       "25         3.7                  3.3         6.7  \n",
       "26         1.9                  1.3         4.1  \n",
       "27           0                    0           0  \n",
       "28           0                    0           0  \n",
       "29           0                    0           0  \n",
       "30        13.5                 18.3        18.3  \n",
       "31        25.3                 30.8        25.0  \n",
       "32        11.8                 12.5         6.7  \n",
       "33     1241119              1636987     1499016  \n",
       "34     1252145              1614171     1498394  \n",
       "35       25045               114000       11835  \n",
       "36       24142               121775       12309  \n",
       "37          13                   18          20  \n",
       "38          21                   22          23  \n",
       "39          16                   21          21  \n",
       "40          18                   18          18  \n",
       "41          25                   25          23  \n",
       "42          22                   21          21  \n",
       "43        13.0                 21.0        20.0  \n",
       "44        14.0                 22.0        21.0  \n",
       "45        14.0                 22.0        20.0  \n",
       "46          14                   18          21  \n",
       "47          21                   21          23  \n",
       "48          17                   20          22  \n",
       "49          21                   21          21  \n",
       "50          25                   25          23  \n",
       "51          23                   23          22  \n",
       "52          18                   18          18  \n",
       "53          24                   22          21  \n",
       "54          20                   19          20  \n",
       "55           0                    0           0  \n",
       "56           0                    0           0  \n",
       "57  2024-07-31           2024-07-31  2024-07-31  \n",
       "58  2024-07-31           2024-07-31  2024-07-31  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumetable(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_cols = [\n",
    "    \"min_tafeel\", \"max_tafeel\", \"mean_tafeel\", \"gap_tafeel\",\n",
    "    \"ta_min_six_am1\", \"ta_max_six_am1\", \"ta_mean_six_am1\", \"ta_min_six_am2\", \"ta_max_six_am2\", \"ta_mean_six_am2\",\n",
    "    \"ta_min_six_pm1\", \"ta_max_six_pm1\", \"ta_mean_six_pm1\", \"ta_min_six_pm2\", \"ta_max_six_pm2\", \"ta_mean_six_pm2\",\n",
    "    \"min_ws\", \"max_ws\", \"mean_ws\",\n",
    "]\n",
    "\n",
    "lag_data_1 = data[lag_cols][17:-17].reset_index(drop=True)\n",
    "lag_data_2 = data[lag_cols][:-34].reset_index(drop=True)\n",
    "lag_data_1.columns =  [\"lag1_\" + col for col in lag_data_1.columns]\n",
    "lag_data_2.columns =  [\"lag2_\" + col for col in lag_data_2.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25976, 19), (25976, 19))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag_data_2.shape, lag_data_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import BinaryEncoder\n",
    "be = BinaryEncoder()\n",
    "\n",
    "sido_en = be.fit_transform(data[\"sido\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25976, 63)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sido_0</th>\n",
       "      <th>sido_1</th>\n",
       "      <th>sido_2</th>\n",
       "      <th>sido_3</th>\n",
       "      <th>sido_4</th>\n",
       "      <th>min_tafeel</th>\n",
       "      <th>max_tafeel</th>\n",
       "      <th>mean_tafeel</th>\n",
       "      <th>gap_tafeel</th>\n",
       "      <th>ta_min_six_am1</th>\n",
       "      <th>...</th>\n",
       "      <th>lag2_ta_mean_six_am2</th>\n",
       "      <th>lag2_ta_min_six_pm1</th>\n",
       "      <th>lag2_ta_max_six_pm1</th>\n",
       "      <th>lag2_ta_mean_six_pm1</th>\n",
       "      <th>lag2_ta_min_six_pm2</th>\n",
       "      <th>lag2_ta_max_six_pm2</th>\n",
       "      <th>lag2_ta_mean_six_pm2</th>\n",
       "      <th>lag2_min_ws</th>\n",
       "      <th>lag2_max_ws</th>\n",
       "      <th>lag2_mean_ws</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.17</td>\n",
       "      <td>18.43</td>\n",
       "      <td>14.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.26</td>\n",
       "      <td>17.55</td>\n",
       "      <td>14.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.07</td>\n",
       "      <td>19.11</td>\n",
       "      <td>15.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.75</td>\n",
       "      <td>18.73</td>\n",
       "      <td>14.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.11</td>\n",
       "      <td>20.11</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25971</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.54</td>\n",
       "      <td>23.87</td>\n",
       "      <td>21.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25972</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.16</td>\n",
       "      <td>24.52</td>\n",
       "      <td>21.6</td>\n",
       "      <td>6.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25973</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.84</td>\n",
       "      <td>23.65</td>\n",
       "      <td>21.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25974</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.86</td>\n",
       "      <td>25.05</td>\n",
       "      <td>23.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25975</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.11</td>\n",
       "      <td>25.09</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25976 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sido_0  sido_1  sido_2  sido_3  sido_4  min_tafeel  max_tafeel  \\\n",
       "0           0       0       0       0       1       10.17       18.43   \n",
       "1           0       0       0       1       0       10.26       17.55   \n",
       "2           0       0       0       1       1       12.07       19.11   \n",
       "3           0       0       1       0       0       10.75       18.73   \n",
       "4           0       0       1       0       1       13.11       20.11   \n",
       "...       ...     ...     ...     ...     ...         ...         ...   \n",
       "25971       0       1       1       0       1       18.54       23.87   \n",
       "25972       0       1       1       1       0       18.16       24.52   \n",
       "25973       0       1       1       1       1       17.84       23.65   \n",
       "25974       1       0       0       0       0       20.86       25.05   \n",
       "25975       1       0       0       0       1       20.11       25.09   \n",
       "\n",
       "       mean_tafeel  gap_tafeel  ta_min_six_am1  ...  lag2_ta_mean_six_am2  \\\n",
       "0             14.4         8.3             9.0  ...                    15   \n",
       "1             14.1         7.3             9.0  ...                    15   \n",
       "2             15.7         7.0            12.0  ...                    17   \n",
       "3             14.7         8.0             8.0  ...                    15   \n",
       "4             17.0         7.0            13.0  ...                    17   \n",
       "...            ...         ...             ...  ...                   ...   \n",
       "25971         21.6         5.3            22.0  ...                    24   \n",
       "25972         21.6         6.4            15.0  ...                    22   \n",
       "25973         21.1         5.8            19.0  ...                    23   \n",
       "25974         23.1         4.2            21.0  ...                    25   \n",
       "25975         23.0         5.0            20.0  ...                    22   \n",
       "\n",
       "       lag2_ta_min_six_pm1  lag2_ta_max_six_pm1  lag2_ta_mean_six_pm1  \\\n",
       "0                       21                   24                    22   \n",
       "1                       21                   23                    22   \n",
       "2                       21                   25                    23   \n",
       "3                       20                   23                    22   \n",
       "4                       22                   25                    24   \n",
       "...                    ...                  ...                   ...   \n",
       "25971                   26                   29                    28   \n",
       "25972                   24                   26                    25   \n",
       "25973                   25                   27                    26   \n",
       "25974                   26                   30                    29   \n",
       "25975                   22                   25                    24   \n",
       "\n",
       "       lag2_ta_min_six_pm2  lag2_ta_max_six_pm2  lag2_ta_mean_six_pm2  \\\n",
       "0                       14                   21                    17   \n",
       "1                       15                   22                    18   \n",
       "2                       18                   24                    20   \n",
       "3                       12                   21                    16   \n",
       "4                       19                   24                    21   \n",
       "...                    ...                  ...                   ...   \n",
       "25971                   23                   26                    24   \n",
       "25972                   20                   24                    21   \n",
       "25973                   20                   25                    22   \n",
       "25974                   21                   26                    23   \n",
       "25975                   20                   22                    21   \n",
       "\n",
       "       lag2_min_ws  lag2_max_ws  lag2_mean_ws  \n",
       "0              0.3          3.5           1.7  \n",
       "1              0.0          3.7           1.6  \n",
       "2              0.1          3.7           1.9  \n",
       "3              0.1          4.1           1.6  \n",
       "4              0.4          4.7           2.3  \n",
       "...            ...          ...           ...  \n",
       "25971          0.7          3.5           2.5  \n",
       "25972          0.0          1.5           0.7  \n",
       "25973          1.1          3.8           2.2  \n",
       "25974          0.0          2.9           1.4  \n",
       "25975          0.0          3.8           2.1  \n",
       "\n",
       "[25976 rows x 63 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.concat()pd.DataFrame([sido_en, data.jenks_cluster])\n",
    "new_data = pd.concat(\n",
    "    [\n",
    "        sido_en, data.min_tafeel, data.max_tafeel, data.mean_tafeel, data.gap_tafeel,\n",
    "        data.ta_min_six_am1, data.ta_max_six_am1, data.ta_mean_six_am1, data.ta_min_six_am2, data.ta_max_six_am2, data.ta_mean_six_am2,\n",
    "        data.ta_min_six_pm1, data.ta_max_six_pm1, data.ta_mean_six_pm1, data.ta_min_six_pm2, data.ta_max_six_pm2, data.ta_mean_six_pm2,\n",
    "        data.min_ws, data.max_ws, data.mean_ws,\n",
    "        data.jenks_cluster,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "new_data = new_data[34:].reset_index(drop=True)\n",
    "new_data = pd.concat([new_data, lag_data_1], axis=1)\n",
    "new_data = pd.concat([new_data, lag_data_2], axis=1)\n",
    "print(new_data.shape)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dev_folder\\온열환자_과제_20240923_Q\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_data.drop(columns=[\"jenks_cluster\"])\n",
    "y = new_data.jenks_cluster\n",
    "\n",
    "seed_num = 43\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=seed_num)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.125, stratify=y_temp, random_state=seed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18702, 62), (2078, 62), (5196, 62))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18702,), (2078,), (5196,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'verbosity': 0,\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
    "        'eval_stopping_rounds': 10,\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(**param)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        verbose=False,\n",
    "    )\n",
    "    \n",
    "    y_pred = model.predict(X_valid)\n",
    "    accuracy = accuracy_score(y_valid, y_pred)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-24 16:15:51,675] A new study created in memory with name: no-name-f3becf4a-8fc0-4921-ab34-fe2f98559bd0\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:15:56,564] Trial 0 finished with value: 0.8435996150144369 and parameters: {'n_estimators': 715, 'max_depth': 8, 'learning_rate': 0.013348136211306162}. Best is trial 0 with value: 0.8435996150144369.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:15:59,280] Trial 1 finished with value: 0.84167468719923 and parameters: {'n_estimators': 908, 'max_depth': 4, 'learning_rate': 0.04518591643758292}. Best is trial 0 with value: 0.8435996150144369.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:16:06,157] Trial 2 finished with value: 0.8455245428296438 and parameters: {'n_estimators': 916, 'max_depth': 8, 'learning_rate': 0.006400895439212625}. Best is trial 2 with value: 0.8455245428296438.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:16:07,781] Trial 3 finished with value: 0.8315688161693936 and parameters: {'n_estimators': 593, 'max_depth': 3, 'learning_rate': 0.002300307328392995}. Best is trial 2 with value: 0.8455245428296438.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:16:09,377] Trial 4 finished with value: 0.8378248315688162 and parameters: {'n_estimators': 592, 'max_depth': 3, 'learning_rate': 0.015697754836975053}. Best is trial 2 with value: 0.8455245428296438.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:16:13,467] Trial 5 finished with value: 0.8435996150144369 and parameters: {'n_estimators': 320, 'max_depth': 9, 'learning_rate': 0.003520478548756767}. Best is trial 2 with value: 0.8455245428296438.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:16:15,795] Trial 6 finished with value: 0.8435996150144369 and parameters: {'n_estimators': 765, 'max_depth': 4, 'learning_rate': 0.018623253766325936}. Best is trial 2 with value: 0.8455245428296438.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:16:17,378] Trial 7 finished with value: 0.8445620789220404 and parameters: {'n_estimators': 157, 'max_depth': 10, 'learning_rate': 0.084788688871825}. Best is trial 2 with value: 0.8455245428296438.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:16:19,466] Trial 8 finished with value: 0.8435996150144369 and parameters: {'n_estimators': 592, 'max_depth': 5, 'learning_rate': 0.023093266354784956}. Best is trial 2 with value: 0.8455245428296438.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:16:25,143] Trial 9 finished with value: 0.8474494706448508 and parameters: {'n_estimators': 996, 'max_depth': 7, 'learning_rate': 0.004809612594990373}. Best is trial 9 with value: 0.8474494706448508.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:16:27,102] Trial 10 finished with value: 0.8358999037536092 and parameters: {'n_estimators': 386, 'max_depth': 6, 'learning_rate': 0.0010125649474717958}. Best is trial 9 with value: 0.8474494706448508.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:16:32,797] Trial 11 finished with value: 0.848893166506256 and parameters: {'n_estimators': 981, 'max_depth': 7, 'learning_rate': 0.005132055974281129}. Best is trial 11 with value: 0.848893166506256.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:16:38,801] Trial 12 finished with value: 0.8493743984600578 and parameters: {'n_estimators': 1000, 'max_depth': 7, 'learning_rate': 0.0056333190056467655}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:16:42,915] Trial 13 finished with value: 0.8431183830606352 and parameters: {'n_estimators': 805, 'max_depth': 6, 'learning_rate': 0.002050851882784116}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:16:48,449] Trial 14 finished with value: 0.8474494706448508 and parameters: {'n_estimators': 988, 'max_depth': 7, 'learning_rate': 0.00809938543525282}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:16:55,780] Trial 15 finished with value: 0.8402309913378249 and parameters: {'n_estimators': 829, 'max_depth': 8, 'learning_rate': 0.003260837235873873}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:17:03,966] Trial 16 finished with value: 0.8474494706448508 and parameters: {'n_estimators': 699, 'max_depth': 10, 'learning_rate': 0.009361716282522135}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:17:05,851] Trial 17 finished with value: 0.8368623676612127 and parameters: {'n_estimators': 446, 'max_depth': 5, 'learning_rate': 0.0016492384318808977}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:17:11,566] Trial 18 finished with value: 0.8445620789220404 and parameters: {'n_estimators': 881, 'max_depth': 7, 'learning_rate': 0.0044184727687653705}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:17:13,423] Trial 19 finished with value: 0.8421559191530318 and parameters: {'n_estimators': 157, 'max_depth': 9, 'learning_rate': 0.02626579297396439}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:17:16,868] Trial 20 finished with value: 0.8440808469682387 and parameters: {'n_estimators': 689, 'max_depth': 6, 'learning_rate': 0.006881518399704869}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:17:22,879] Trial 21 finished with value: 0.8479307025986526 and parameters: {'n_estimators': 995, 'max_depth': 7, 'learning_rate': 0.005512214118762923}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:17:29,097] Trial 22 finished with value: 0.848893166506256 and parameters: {'n_estimators': 999, 'max_depth': 7, 'learning_rate': 0.005466911089740731}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:17:37,522] Trial 23 finished with value: 0.8407122232916265 and parameters: {'n_estimators': 910, 'max_depth': 8, 'learning_rate': 0.002958843017326912}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:17:40,864] Trial 24 finished with value: 0.8460057747834456 and parameters: {'n_estimators': 845, 'max_depth': 5, 'learning_rate': 0.011766534220997082}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:17:52,650] Trial 25 finished with value: 0.8402309913378249 and parameters: {'n_estimators': 943, 'max_depth': 9, 'learning_rate': 0.0014019448855291457}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:17:56,414] Trial 26 finished with value: 0.8469682386910491 and parameters: {'n_estimators': 795, 'max_depth': 6, 'learning_rate': 0.009867794256672793}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:18:02,653] Trial 27 finished with value: 0.8440808469682387 and parameters: {'n_estimators': 946, 'max_depth': 7, 'learning_rate': 0.004461193791983151}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:18:07,794] Trial 28 finished with value: 0.8387872954764196 and parameters: {'n_estimators': 501, 'max_depth': 8, 'learning_rate': 0.0027685173856408897}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:18:11,384] Trial 29 finished with value: 0.8445620789220404 and parameters: {'n_estimators': 722, 'max_depth': 6, 'learning_rate': 0.0117292918922151}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:18:17,753] Trial 30 finished with value: 0.8431183830606352 and parameters: {'n_estimators': 871, 'max_depth': 8, 'learning_rate': 0.0350566715386217}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:18:24,172] Trial 31 finished with value: 0.848893166506256 and parameters: {'n_estimators': 990, 'max_depth': 7, 'learning_rate': 0.00575165437828884}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:18:30,065] Trial 32 finished with value: 0.8479307025986526 and parameters: {'n_estimators': 957, 'max_depth': 7, 'learning_rate': 0.007347249169394273}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:18:37,970] Trial 33 finished with value: 0.8460057747834456 and parameters: {'n_estimators': 913, 'max_depth': 8, 'learning_rate': 0.005779937770544427}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:18:45,080] Trial 34 finished with value: 0.8440808469682387 and parameters: {'n_estimators': 997, 'max_depth': 7, 'learning_rate': 0.003982212284802388}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:18:49,364] Trial 35 finished with value: 0.8460057747834456 and parameters: {'n_estimators': 874, 'max_depth': 6, 'learning_rate': 0.014372279926226455}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:18:58,206] Trial 36 finished with value: 0.8421559191530318 and parameters: {'n_estimators': 750, 'max_depth': 9, 'learning_rate': 0.006562260882859764}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:19:02,410] Trial 37 finished with value: 0.8392685274302214 and parameters: {'n_estimators': 944, 'max_depth': 5, 'learning_rate': 0.002432838282402088}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:19:08,681] Trial 38 finished with value: 0.84167468719923 and parameters: {'n_estimators': 898, 'max_depth': 7, 'learning_rate': 0.0036480942335029094}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:19:15,955] Trial 39 finished with value: 0.8431183830606352 and parameters: {'n_estimators': 648, 'max_depth': 9, 'learning_rate': 0.008231017861988842}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:19:20,548] Trial 40 finished with value: 0.8445620789220404 and parameters: {'n_estimators': 833, 'max_depth': 6, 'learning_rate': 0.005254536735918412}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:19:26,939] Trial 41 finished with value: 0.848893166506256 and parameters: {'n_estimators': 992, 'max_depth': 7, 'learning_rate': 0.006156854558910748}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:19:35,178] Trial 42 finished with value: 0.8450433108758422 and parameters: {'n_estimators': 953, 'max_depth': 8, 'learning_rate': 0.00579574122730327}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:19:36,764] Trial 43 finished with value: 0.8479307025986526 and parameters: {'n_estimators': 264, 'max_depth': 7, 'learning_rate': 0.08812848034526095}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:19:43,221] Trial 44 finished with value: 0.8435996150144369 and parameters: {'n_estimators': 966, 'max_depth': 8, 'learning_rate': 0.017160346686442788}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:19:48,857] Trial 45 finished with value: 0.8479307025986526 and parameters: {'n_estimators': 927, 'max_depth': 7, 'learning_rate': 0.011620006142460369}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:19:53,239] Trial 46 finished with value: 0.8426371511068335 and parameters: {'n_estimators': 788, 'max_depth': 6, 'learning_rate': 0.0037596013738573158}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:20:00,800] Trial 47 finished with value: 0.8426371511068335 and parameters: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.008388336351485753}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:20:03,821] Trial 48 finished with value: 0.8349374398460058 and parameters: {'n_estimators': 861, 'max_depth': 4, 'learning_rate': 0.0019178637171975955}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:20:09,922] Trial 49 finished with value: 0.8464870067372473 and parameters: {'n_estimators': 910, 'max_depth': 7, 'learning_rate': 0.004746930903510887}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:20:14,597] Trial 50 finished with value: 0.8460057747834456 and parameters: {'n_estimators': 969, 'max_depth': 6, 'learning_rate': 0.0068246882699875295}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:20:20,895] Trial 51 finished with value: 0.8479307025986526 and parameters: {'n_estimators': 997, 'max_depth': 7, 'learning_rate': 0.004955957489033646}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:20:26,160] Trial 52 finished with value: 0.8411934552454283 and parameters: {'n_estimators': 971, 'max_depth': 7, 'learning_rate': 0.0633948504931906}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:20:31,952] Trial 53 finished with value: 0.8484119345524542 and parameters: {'n_estimators': 919, 'max_depth': 7, 'learning_rate': 0.005895185652153348}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:20:40,396] Trial 54 finished with value: 0.84167468719923 and parameters: {'n_estimators': 912, 'max_depth': 8, 'learning_rate': 0.0030983423445379164}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:20:45,733] Trial 55 finished with value: 0.8479307025986526 and parameters: {'n_estimators': 891, 'max_depth': 7, 'learning_rate': 0.009115085588470257}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:20:50,046] Trial 56 finished with value: 0.8440808469682387 and parameters: {'n_estimators': 831, 'max_depth': 6, 'learning_rate': 0.004237997703052452}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:20:55,788] Trial 57 finished with value: 0.848893166506256 and parameters: {'n_estimators': 933, 'max_depth': 7, 'learning_rate': 0.005895936530158511}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:20:57,994] Trial 58 finished with value: 0.8392685274302214 and parameters: {'n_estimators': 535, 'max_depth': 5, 'learning_rate': 0.007358257822314828}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:21:06,719] Trial 59 finished with value: 0.8392685274302214 and parameters: {'n_estimators': 966, 'max_depth': 8, 'learning_rate': 0.002669538840901111}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:21:11,011] Trial 60 finished with value: 0.8460057747834456 and parameters: {'n_estimators': 937, 'max_depth': 6, 'learning_rate': 0.020790173248455647}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:21:16,705] Trial 61 finished with value: 0.8493743984600578 and parameters: {'n_estimators': 928, 'max_depth': 7, 'learning_rate': 0.006005579323002732}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:21:21,885] Trial 62 finished with value: 0.8479307025986526 and parameters: {'n_estimators': 877, 'max_depth': 7, 'learning_rate': 0.010263348137415326}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:21:28,623] Trial 63 finished with value: 0.84167468719923 and parameters: {'n_estimators': 975, 'max_depth': 7, 'learning_rate': 0.0035224544232087267}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:21:34,591] Trial 64 finished with value: 0.8493743984600578 and parameters: {'n_estimators': 936, 'max_depth': 7, 'learning_rate': 0.006209178630407331}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:21:41,712] Trial 65 finished with value: 0.8431183830606352 and parameters: {'n_estimators': 816, 'max_depth': 8, 'learning_rate': 0.004931297032105399}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:21:43,794] Trial 66 finished with value: 0.8435996150144369 and parameters: {'n_estimators': 376, 'max_depth': 6, 'learning_rate': 0.0075993762071954}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:21:49,496] Trial 67 finished with value: 0.8426371511068335 and parameters: {'n_estimators': 855, 'max_depth': 7, 'learning_rate': 0.004244005853203985}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:21:55,629] Trial 68 finished with value: 0.8484119345524542 and parameters: {'n_estimators': 983, 'max_depth': 7, 'learning_rate': 0.006666383558331634}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:22:02,638] Trial 69 finished with value: 0.8431183830606352 and parameters: {'n_estimators': 945, 'max_depth': 8, 'learning_rate': 0.010213934296706546}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:22:06,882] Trial 70 finished with value: 0.8445620789220404 and parameters: {'n_estimators': 896, 'max_depth': 6, 'learning_rate': 0.012812616661390056}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:22:12,828] Trial 71 finished with value: 0.848893166506256 and parameters: {'n_estimators': 933, 'max_depth': 7, 'learning_rate': 0.005900795194793903}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:22:19,113] Trial 72 finished with value: 0.8484119345524542 and parameters: {'n_estimators': 972, 'max_depth': 7, 'learning_rate': 0.005095289545471997}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:22:25,317] Trial 73 finished with value: 0.8493743984600578 and parameters: {'n_estimators': 998, 'max_depth': 7, 'learning_rate': 0.006474346154966023}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:22:31,262] Trial 74 finished with value: 0.8479307025986526 and parameters: {'n_estimators': 999, 'max_depth': 7, 'learning_rate': 0.0086882011471595}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:22:37,777] Trial 75 finished with value: 0.84167468719923 and parameters: {'n_estimators': 956, 'max_depth': 7, 'learning_rate': 0.0033751525698925595}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:22:39,094] Trial 76 finished with value: 0.8397497593840231 and parameters: {'n_estimators': 128, 'max_depth': 8, 'learning_rate': 0.0063650517684087984}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:22:43,770] Trial 77 finished with value: 0.8440808469682387 and parameters: {'n_estimators': 889, 'max_depth': 6, 'learning_rate': 0.004520348480696695}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:22:51,212] Trial 78 finished with value: 0.8435996150144369 and parameters: {'n_estimators': 977, 'max_depth': 8, 'learning_rate': 0.00779556503113942}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:22:57,114] Trial 79 finished with value: 0.8484119345524542 and parameters: {'n_estimators': 922, 'max_depth': 7, 'learning_rate': 0.005494519607810864}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:23:01,579] Trial 80 finished with value: 0.8435996150144369 and parameters: {'n_estimators': 851, 'max_depth': 6, 'learning_rate': 0.0039692985105135884}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:23:07,339] Trial 81 finished with value: 0.8493743984600578 and parameters: {'n_estimators': 943, 'max_depth': 7, 'learning_rate': 0.006200146735450522}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:23:11,651] Trial 82 finished with value: 0.8464870067372473 and parameters: {'n_estimators': 645, 'max_depth': 7, 'learning_rate': 0.006641484334894167}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:23:17,303] Trial 83 finished with value: 0.848893166506256 and parameters: {'n_estimators': 952, 'max_depth': 7, 'learning_rate': 0.007562640324778876}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:23:23,503] Trial 84 finished with value: 0.848893166506256 and parameters: {'n_estimators': 998, 'max_depth': 7, 'learning_rate': 0.005219510303518453}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:23:30,298] Trial 85 finished with value: 0.8435996150144369 and parameters: {'n_estimators': 949, 'max_depth': 8, 'learning_rate': 0.009353477032456098}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:23:35,881] Trial 86 finished with value: 0.8493743984600578 and parameters: {'n_estimators': 902, 'max_depth': 7, 'learning_rate': 0.0061363810257923646}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:23:40,987] Trial 87 finished with value: 0.8474494706448508 and parameters: {'n_estimators': 899, 'max_depth': 7, 'learning_rate': 0.011023460379354146}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:23:45,077] Trial 88 finished with value: 0.8431183830606352 and parameters: {'n_estimators': 780, 'max_depth': 6, 'learning_rate': 0.003978145088057749}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:23:47,261] Trial 89 finished with value: 0.84167468719923 and parameters: {'n_estimators': 231, 'max_depth': 8, 'learning_rate': 0.0046284446155521256}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:23:52,441] Trial 90 finished with value: 0.848893166506256 and parameters: {'n_estimators': 869, 'max_depth': 7, 'learning_rate': 0.007192178736569468}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:23:58,674] Trial 91 finished with value: 0.8493743984600578 and parameters: {'n_estimators': 984, 'max_depth': 7, 'learning_rate': 0.006284996371640024}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:24:04,965] Trial 92 finished with value: 0.8479307025986526 and parameters: {'n_estimators': 975, 'max_depth': 7, 'learning_rate': 0.0052203217012824574}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:24:10,477] Trial 93 finished with value: 0.8474494706448508 and parameters: {'n_estimators': 922, 'max_depth': 7, 'learning_rate': 0.008392888125751691}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:24:16,362] Trial 94 finished with value: 0.848893166506256 and parameters: {'n_estimators': 956, 'max_depth': 7, 'learning_rate': 0.006367504677299707}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:24:22,265] Trial 95 finished with value: 0.8479307025986526 and parameters: {'n_estimators': 931, 'max_depth': 7, 'learning_rate': 0.005406578916328262}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:24:26,982] Trial 96 finished with value: 0.8469682386910491 and parameters: {'n_estimators': 981, 'max_depth': 6, 'learning_rate': 0.007004203890845425}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:24:32,883] Trial 97 finished with value: 0.8435996150144369 and parameters: {'n_estimators': 910, 'max_depth': 7, 'learning_rate': 0.004379658683778275}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:24:40,348] Trial 98 finished with value: 0.8464870067372473 and parameters: {'n_estimators': 961, 'max_depth': 8, 'learning_rate': 0.006152867836837682}. Best is trial 12 with value: 0.8493743984600578.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14528\\3487477584.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:24:43,462] Trial 99 finished with value: 0.8440808469682387 and parameters: {'n_estimators': 445, 'max_depth': 7, 'learning_rate': 0.0031904536298567386}. Best is trial 12 with value: 0.8493743984600578.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 0.8493743984600578\n",
      "Best parameters: {'n_estimators': 1000, 'max_depth': 7, 'learning_rate': 0.0056333190056467655}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(f\"Best trial: {study.best_trial.value}\")\n",
    "print(f\"Best parameters: {study.best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 최적의 모델로 최종 테스트 데이터 성능 평가\n",
    "best_model = XGBClassifier(**study.best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "preds = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix # 혼동행렬\n",
    "from sklearn.metrics import accuracy_score # 정확도\n",
    "from sklearn.metrics import precision_score # 정밀도\n",
    "from sklearn.metrics import recall_score # 재현율\n",
    "from sklearn.metrics import f1_score # f1 스코어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_class_score(y_test, preds, type_average=\"macro\"):\n",
    "    mask_class_0 = y_test == 0\n",
    "    mask_class_1 = y_test == 1\n",
    "    mask_class_2 = y_test == 2\n",
    "    \n",
    "    results = pd.DataFrame(\n",
    "        {\n",
    "            \"class0\": cal_matrix(y_test[mask_class_0], preds[mask_class_0], type_average),\n",
    "            \"class1\": cal_matrix(y_test[mask_class_1], preds[mask_class_1], type_average),\n",
    "            \"class2\": cal_matrix(y_test[mask_class_2], preds[mask_class_2], type_average),\n",
    "        }\n",
    "    )\n",
    "    results = results.T\n",
    "    results.columns = [\"accuracy\", \"precision\", \"recall\", \"F1\"]\n",
    "    return results\n",
    "\n",
    "def cal_matrix(y_test, preds, type_average):\n",
    "    result_class = []\n",
    "    result_class.append(accuracy_score(y_test, preds))\n",
    "    result_class.append(precision_score(y_test, preds, average=type_average).tolist())\n",
    "    result_class.append(recall_score(y_test, preds, average=type_average).tolist())\n",
    "    result_class.append(f1_score(y_test, preds, average=type_average).tolist())\n",
    "    return result_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dev_folder\\온열환자_과제_20240923_Q\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Dev_folder\\온열환자_과제_20240923_Q\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Dev_folder\\온열환자_과제_20240923_Q\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "test = cal_class_score(y_test, preds, type_average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class0</th>\n",
       "      <td>0.942828</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.471414</td>\n",
       "      <td>0.485287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class1</th>\n",
       "      <td>0.588448</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.196149</td>\n",
       "      <td>0.246970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class2</th>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.197183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision    recall        F1\n",
       "class0  0.942828   0.500000  0.471414  0.485287\n",
       "class1  0.588448   0.333333  0.196149  0.246970\n",
       "class2  0.420000   0.333333  0.140000  0.197183"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.895     0.943     0.918      3988\n",
      "           1      0.697     0.588     0.638      1108\n",
      "           2      0.724     0.420     0.532       100\n",
      "\n",
      "    accuracy                          0.857      5196\n",
      "   macro avg      0.772     0.650     0.696      5196\n",
      "weighted avg      0.849     0.857     0.851      5196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

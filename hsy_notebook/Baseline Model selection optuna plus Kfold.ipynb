{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumetable(df):\n",
    "    print(f'Dataset shape: {df.shape}')\n",
    "    summary = pd.DataFrame(df.dtypes, columns=[' Type'])\n",
    "    summary = summary.reset_index()\n",
    "    summary = summary.rename(columns={'index': 'Feature'})\n",
    "    summary['Missing Values Count'] = df.isnull().sum().values\n",
    "    summary['Missing Values Percentage'] = df.isnull().sum().values / len(df) * 100\n",
    "    summary['Unique Values Count'] = df.nunique().values\n",
    "    summary['First Value'] = df.iloc[0].values\n",
    "    summary['Second Value'] = df.iloc[1].values\n",
    "    summary['Third Value'] = df.iloc[2].values\n",
    "    summary['Second to Last Value'] = df.iloc[-2].values\n",
    "    summary['Last Value'] = df.iloc[-1].values\n",
    "    return summary\n",
    "\n",
    "def seed_everything(seed = 9234):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    # torch.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed(seed)\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    # torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Data/Soo_T_PATIENTS_DAILY_WHOLE_0812.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (26010, 59)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Type</th>\n",
       "      <th>Missing Values Count</th>\n",
       "      <th>Missing Values Percentage</th>\n",
       "      <th>Unique Values Count</th>\n",
       "      <th>First Value</th>\n",
       "      <th>Second Value</th>\n",
       "      <th>Third Value</th>\n",
       "      <th>Second to Last Value</th>\n",
       "      <th>Last Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sido</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>경기도</td>\n",
       "      <td>충청북도</td>\n",
       "      <td>대구광역시</td>\n",
       "      <td>경상남도</td>\n",
       "      <td>인천광역시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>create_date</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1530</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>2023-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sido_cd</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weekend_yn</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grid_x</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>89</td>\n",
       "      <td>91</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>grid_y</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>120</td>\n",
       "      <td>107</td>\n",
       "      <td>90</td>\n",
       "      <td>77</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sat_x</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sat_y</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>min_ta</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253</td>\n",
       "      <td>9.6</td>\n",
       "      <td>10.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>18.3</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_ta</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>259</td>\n",
       "      <td>24.2</td>\n",
       "      <td>23.7</td>\n",
       "      <td>25.3</td>\n",
       "      <td>25.5</td>\n",
       "      <td>23.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mean_ta</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231</td>\n",
       "      <td>16.6</td>\n",
       "      <td>17.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gap_ta</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>194</td>\n",
       "      <td>14.6</td>\n",
       "      <td>13.2</td>\n",
       "      <td>11.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>min_tafeel</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2144</td>\n",
       "      <td>12.35</td>\n",
       "      <td>12.78</td>\n",
       "      <td>16.29</td>\n",
       "      <td>20.86</td>\n",
       "      <td>20.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max_tafeel</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1943</td>\n",
       "      <td>22.04</td>\n",
       "      <td>22.16</td>\n",
       "      <td>23.66</td>\n",
       "      <td>25.05</td>\n",
       "      <td>25.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mean_tafeel</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>19.6</td>\n",
       "      <td>23.1</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gap_tafeel</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142</td>\n",
       "      <td>9.7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>min_hm</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max_hm</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73</td>\n",
       "      <td>98.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mean_hm</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>739</td>\n",
       "      <td>61.1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>64.7</td>\n",
       "      <td>76.7</td>\n",
       "      <td>75.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gap_hm</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>min_wbtemp</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246</td>\n",
       "      <td>8.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>12.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>max_wbtemp</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234</td>\n",
       "      <td>14.2</td>\n",
       "      <td>14.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mean_wbtemp</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229</td>\n",
       "      <td>11.6</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>18.4</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gap_wbtemp</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>min_ws</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>max_ws</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mean_ws</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tropical_3days</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>heatwave_temp</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>heatalert_temp</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ta_min_3days</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243</td>\n",
       "      <td>9.6</td>\n",
       "      <td>10.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>18.3</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ta_max_3days</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246</td>\n",
       "      <td>24.2</td>\n",
       "      <td>23.7</td>\n",
       "      <td>25.3</td>\n",
       "      <td>30.8</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>gap_ta_minmax</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>213</td>\n",
       "      <td>14.6</td>\n",
       "      <td>13.2</td>\n",
       "      <td>11.8</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>popular_man</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170</td>\n",
       "      <td>6219813</td>\n",
       "      <td>796141</td>\n",
       "      <td>1241119</td>\n",
       "      <td>1636987</td>\n",
       "      <td>1499016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>popular_woman</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170</td>\n",
       "      <td>6138017</td>\n",
       "      <td>782792</td>\n",
       "      <td>1252145</td>\n",
       "      <td>1614171</td>\n",
       "      <td>1498394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>agriculture_man</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169</td>\n",
       "      <td>186278</td>\n",
       "      <td>92687</td>\n",
       "      <td>25045</td>\n",
       "      <td>114000</td>\n",
       "      <td>11835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>agriculture_woman</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169</td>\n",
       "      <td>188594</td>\n",
       "      <td>95065</td>\n",
       "      <td>24142</td>\n",
       "      <td>121775</td>\n",
       "      <td>12309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ta_min_am</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ta_max_am</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ta_mean_am</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ta_min_pm</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ta_max_pm</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ta_mean_pm</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ta_min_six_am1</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ta_max_six_am1</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ta_mean_six_am1</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ta_min_six_am2</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ta_max_six_am2</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ta_mean_six_am2</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ta_min_six_pm1</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ta_max_six_pm1</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ta_mean_six_pm1</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ta_min_six_pm2</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ta_max_six_pm2</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ta_mean_six_pm2</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>patientsCnt</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>jenks_cluster</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>instDate</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>2024-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>updtDate</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>2024-07-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature     Type  Missing Values Count  \\\n",
       "0                sido   object                     0   \n",
       "1         create_date   object                     0   \n",
       "2             sido_cd    int64                     0   \n",
       "3          weekend_yn    int64                     0   \n",
       "4              grid_x    int64                     0   \n",
       "5              grid_y    int64                     0   \n",
       "6               sat_x  float64                     0   \n",
       "7               sat_y  float64                     0   \n",
       "8              min_ta  float64                     0   \n",
       "9              max_ta  float64                     0   \n",
       "10            mean_ta  float64                     0   \n",
       "11             gap_ta  float64                     0   \n",
       "12         min_tafeel  float64                     0   \n",
       "13         max_tafeel  float64                     0   \n",
       "14        mean_tafeel  float64                     0   \n",
       "15         gap_tafeel  float64                     0   \n",
       "16             min_hm  float64                     0   \n",
       "17             max_hm  float64                     0   \n",
       "18            mean_hm  float64                     0   \n",
       "19             gap_hm  float64                     0   \n",
       "20         min_wbtemp  float64                     0   \n",
       "21         max_wbtemp  float64                     0   \n",
       "22        mean_wbtemp  float64                     0   \n",
       "23         gap_wbtemp  float64                     0   \n",
       "24             min_ws  float64                     0   \n",
       "25             max_ws  float64                     0   \n",
       "26            mean_ws  float64                     0   \n",
       "27     tropical_3days    int64                     0   \n",
       "28      heatwave_temp    int64                     0   \n",
       "29     heatalert_temp    int64                     0   \n",
       "30       ta_min_3days  float64                     0   \n",
       "31       ta_max_3days  float64                     0   \n",
       "32      gap_ta_minmax  float64                     0   \n",
       "33        popular_man    int64                     0   \n",
       "34      popular_woman    int64                     0   \n",
       "35    agriculture_man    int64                     0   \n",
       "36  agriculture_woman    int64                     0   \n",
       "37          ta_min_am    int64                     0   \n",
       "38          ta_max_am    int64                     0   \n",
       "39         ta_mean_am    int64                     0   \n",
       "40          ta_min_pm    int64                     0   \n",
       "41          ta_max_pm    int64                     0   \n",
       "42         ta_mean_pm    int64                     0   \n",
       "43     ta_min_six_am1  float64                     0   \n",
       "44     ta_max_six_am1  float64                     0   \n",
       "45    ta_mean_six_am1  float64                     0   \n",
       "46     ta_min_six_am2    int64                     0   \n",
       "47     ta_max_six_am2    int64                     0   \n",
       "48    ta_mean_six_am2    int64                     0   \n",
       "49     ta_min_six_pm1    int64                     0   \n",
       "50     ta_max_six_pm1    int64                     0   \n",
       "51    ta_mean_six_pm1    int64                     0   \n",
       "52     ta_min_six_pm2    int64                     0   \n",
       "53     ta_max_six_pm2    int64                     0   \n",
       "54    ta_mean_six_pm2    int64                     0   \n",
       "55        patientsCnt    int64                     0   \n",
       "56      jenks_cluster    int64                     0   \n",
       "57           instDate   object                     0   \n",
       "58           updtDate   object                     0   \n",
       "\n",
       "    Missing Values Percentage  Unique Values Count First Value Second Value  \\\n",
       "0                         0.0                   17         경기도         충청북도   \n",
       "1                         0.0                 1530  2014-05-01   2014-05-01   \n",
       "2                         0.0                   17          31           33   \n",
       "3                         0.0                    2           0            0   \n",
       "4                         0.0                   15          60           69   \n",
       "5                         0.0                   16         120          107   \n",
       "6                         0.0                    1         0.0          0.0   \n",
       "7                         0.0                    1         0.0          0.0   \n",
       "8                         0.0                  253         9.6         10.5   \n",
       "9                         0.0                  259        24.2         23.7   \n",
       "10                        0.0                  231        16.6         17.1   \n",
       "11                        0.0                  194        14.6         13.2   \n",
       "12                        0.0                 2144       12.35        12.78   \n",
       "13                        0.0                 1943       22.04        22.16   \n",
       "14                        0.0                  223        17.0         17.5   \n",
       "15                        0.0                  142         9.7          9.4   \n",
       "16                        0.0                   97        30.0         33.0   \n",
       "17                        0.0                   73        98.0         91.0   \n",
       "18                        0.0                  739        61.1         60.0   \n",
       "19                        0.0                  120         5.4          5.6   \n",
       "20                        0.0                  246         8.8          9.3   \n",
       "21                        0.0                  234        14.2         14.9   \n",
       "22                        0.0                  229        11.6         12.0   \n",
       "23                        0.0                  120         5.4          5.6   \n",
       "24                        0.0                   76         0.3          0.0   \n",
       "25                        0.0                   91         3.5          3.7   \n",
       "26                        0.0                   96         1.7          1.6   \n",
       "27                        0.0                    4           0            0   \n",
       "28                        0.0                   49           0            0   \n",
       "29                        0.0                   37           0            0   \n",
       "30                        0.0                  243         9.6         10.5   \n",
       "31                        0.0                  246        24.2         23.7   \n",
       "32                        0.0                  213        14.6         13.2   \n",
       "33                        0.0                  170     6219813       796141   \n",
       "34                        0.0                  170     6138017       782792   \n",
       "35                        0.0                  169      186278        92687   \n",
       "36                        0.0                  169      188594        95065   \n",
       "37                        0.0                   28           9           10   \n",
       "38                        0.0                   30          21           21   \n",
       "39                        0.0                   25          13           14   \n",
       "40                        0.0                   27          14           15   \n",
       "41                        0.0                   30          24           23   \n",
       "42                        0.0                   28          20           20   \n",
       "43                        0.0                   29         9.0         10.0   \n",
       "44                        0.0                   27        13.0         14.0   \n",
       "45                        0.0                   27        10.0         12.0   \n",
       "46                        0.0                   28           9           10   \n",
       "47                        0.0                   30          21           21   \n",
       "48                        0.0                   26          15           15   \n",
       "49                        0.0                   29          21           21   \n",
       "50                        0.0                   30          24           23   \n",
       "51                        0.0                   29          22           22   \n",
       "52                        0.0                   27          14           15   \n",
       "53                        0.0                   30          21           22   \n",
       "54                        0.0                   28          17           18   \n",
       "55                        0.0                   42           0            0   \n",
       "56                        0.0                    3           0            0   \n",
       "57                        0.0                    1  2024-07-31   2024-07-31   \n",
       "58                        0.0                    1  2024-07-31   2024-07-31   \n",
       "\n",
       "   Third Value Second to Last Value  Last Value  \n",
       "0        대구광역시                 경상남도       인천광역시  \n",
       "1   2014-05-01           2023-09-30  2023-09-30  \n",
       "2           22                   38          23  \n",
       "3            0                    1           1  \n",
       "4           89                   91          55  \n",
       "5           90                   77         124  \n",
       "6          0.0                  0.0         0.0  \n",
       "7          0.0                  0.0         0.0  \n",
       "8         13.5                 18.3        18.9  \n",
       "9         25.3                 25.5        23.3  \n",
       "10        19.0                 21.5        21.5  \n",
       "11        11.8                  7.2         4.4  \n",
       "12       16.29                20.86       20.11  \n",
       "13       23.66                25.05       25.09  \n",
       "14        19.6                 23.1        23.0  \n",
       "15         7.4                  4.2         5.0  \n",
       "16        27.0                 49.0        62.0  \n",
       "17        97.0                 94.0        84.0  \n",
       "18        64.7                 76.7        75.3  \n",
       "19         3.4                  4.7         5.1  \n",
       "20        12.7                 15.9        15.3  \n",
       "21        16.1                 20.6        20.4  \n",
       "22        14.2                 18.4        18.3  \n",
       "23         3.4                  4.7         5.1  \n",
       "24         0.1                  0.0         0.2  \n",
       "25         3.7                  3.3         6.7  \n",
       "26         1.9                  1.3         4.1  \n",
       "27           0                    0           0  \n",
       "28           0                    0           0  \n",
       "29           0                    0           0  \n",
       "30        13.5                 18.3        18.3  \n",
       "31        25.3                 30.8        25.0  \n",
       "32        11.8                 12.5         6.7  \n",
       "33     1241119              1636987     1499016  \n",
       "34     1252145              1614171     1498394  \n",
       "35       25045               114000       11835  \n",
       "36       24142               121775       12309  \n",
       "37          13                   18          20  \n",
       "38          21                   22          23  \n",
       "39          16                   21          21  \n",
       "40          18                   18          18  \n",
       "41          25                   25          23  \n",
       "42          22                   21          21  \n",
       "43        13.0                 21.0        20.0  \n",
       "44        14.0                 22.0        21.0  \n",
       "45        14.0                 22.0        20.0  \n",
       "46          14                   18          21  \n",
       "47          21                   21          23  \n",
       "48          17                   20          22  \n",
       "49          21                   21          21  \n",
       "50          25                   25          23  \n",
       "51          23                   23          22  \n",
       "52          18                   18          18  \n",
       "53          24                   22          21  \n",
       "54          20                   19          20  \n",
       "55           0                    0           0  \n",
       "56           0                    0           0  \n",
       "57  2024-07-31           2024-07-31  2024-07-31  \n",
       "58  2024-07-31           2024-07-31  2024-07-31  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumetable(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_cols = [\n",
    "    \"min_tafeel\", \"max_tafeel\", \"mean_tafeel\", \"gap_tafeel\",\n",
    "    \"ta_min_six_am1\", \"ta_max_six_am1\", \"ta_mean_six_am1\", \"ta_min_six_am2\", \"ta_max_six_am2\", \"ta_mean_six_am2\",\n",
    "    \"ta_min_six_pm1\", \"ta_max_six_pm1\", \"ta_mean_six_pm1\", \"ta_min_six_pm2\", \"ta_max_six_pm2\", \"ta_mean_six_pm2\",\n",
    "    \"min_ws\", \"max_ws\", \"mean_ws\",\n",
    "]\n",
    "\n",
    "lag_data_1 = data[lag_cols][17:-17].reset_index(drop=True)\n",
    "lag_data_2 = data[lag_cols][:-34].reset_index(drop=True)\n",
    "lag_data_1.columns =  [\"lag1_\" + col for col in lag_data_1.columns]\n",
    "lag_data_2.columns =  [\"lag2_\" + col for col in lag_data_2.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25976, 19), (25976, 19))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag_data_2.shape, lag_data_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import BinaryEncoder\n",
    "be = BinaryEncoder()\n",
    "\n",
    "sido_en = be.fit_transform(data[\"sido\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25976, 63)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sido_0</th>\n",
       "      <th>sido_1</th>\n",
       "      <th>sido_2</th>\n",
       "      <th>sido_3</th>\n",
       "      <th>sido_4</th>\n",
       "      <th>min_tafeel</th>\n",
       "      <th>max_tafeel</th>\n",
       "      <th>mean_tafeel</th>\n",
       "      <th>gap_tafeel</th>\n",
       "      <th>ta_min_six_am1</th>\n",
       "      <th>...</th>\n",
       "      <th>lag2_ta_mean_six_am2</th>\n",
       "      <th>lag2_ta_min_six_pm1</th>\n",
       "      <th>lag2_ta_max_six_pm1</th>\n",
       "      <th>lag2_ta_mean_six_pm1</th>\n",
       "      <th>lag2_ta_min_six_pm2</th>\n",
       "      <th>lag2_ta_max_six_pm2</th>\n",
       "      <th>lag2_ta_mean_six_pm2</th>\n",
       "      <th>lag2_min_ws</th>\n",
       "      <th>lag2_max_ws</th>\n",
       "      <th>lag2_mean_ws</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.17</td>\n",
       "      <td>18.43</td>\n",
       "      <td>14.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.26</td>\n",
       "      <td>17.55</td>\n",
       "      <td>14.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.07</td>\n",
       "      <td>19.11</td>\n",
       "      <td>15.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.75</td>\n",
       "      <td>18.73</td>\n",
       "      <td>14.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.11</td>\n",
       "      <td>20.11</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25971</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.54</td>\n",
       "      <td>23.87</td>\n",
       "      <td>21.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25972</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.16</td>\n",
       "      <td>24.52</td>\n",
       "      <td>21.6</td>\n",
       "      <td>6.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25973</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.84</td>\n",
       "      <td>23.65</td>\n",
       "      <td>21.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25974</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.86</td>\n",
       "      <td>25.05</td>\n",
       "      <td>23.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25975</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.11</td>\n",
       "      <td>25.09</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25976 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sido_0  sido_1  sido_2  sido_3  sido_4  min_tafeel  max_tafeel  \\\n",
       "0           0       0       0       0       1       10.17       18.43   \n",
       "1           0       0       0       1       0       10.26       17.55   \n",
       "2           0       0       0       1       1       12.07       19.11   \n",
       "3           0       0       1       0       0       10.75       18.73   \n",
       "4           0       0       1       0       1       13.11       20.11   \n",
       "...       ...     ...     ...     ...     ...         ...         ...   \n",
       "25971       0       1       1       0       1       18.54       23.87   \n",
       "25972       0       1       1       1       0       18.16       24.52   \n",
       "25973       0       1       1       1       1       17.84       23.65   \n",
       "25974       1       0       0       0       0       20.86       25.05   \n",
       "25975       1       0       0       0       1       20.11       25.09   \n",
       "\n",
       "       mean_tafeel  gap_tafeel  ta_min_six_am1  ...  lag2_ta_mean_six_am2  \\\n",
       "0             14.4         8.3             9.0  ...                    15   \n",
       "1             14.1         7.3             9.0  ...                    15   \n",
       "2             15.7         7.0            12.0  ...                    17   \n",
       "3             14.7         8.0             8.0  ...                    15   \n",
       "4             17.0         7.0            13.0  ...                    17   \n",
       "...            ...         ...             ...  ...                   ...   \n",
       "25971         21.6         5.3            22.0  ...                    24   \n",
       "25972         21.6         6.4            15.0  ...                    22   \n",
       "25973         21.1         5.8            19.0  ...                    23   \n",
       "25974         23.1         4.2            21.0  ...                    25   \n",
       "25975         23.0         5.0            20.0  ...                    22   \n",
       "\n",
       "       lag2_ta_min_six_pm1  lag2_ta_max_six_pm1  lag2_ta_mean_six_pm1  \\\n",
       "0                       21                   24                    22   \n",
       "1                       21                   23                    22   \n",
       "2                       21                   25                    23   \n",
       "3                       20                   23                    22   \n",
       "4                       22                   25                    24   \n",
       "...                    ...                  ...                   ...   \n",
       "25971                   26                   29                    28   \n",
       "25972                   24                   26                    25   \n",
       "25973                   25                   27                    26   \n",
       "25974                   26                   30                    29   \n",
       "25975                   22                   25                    24   \n",
       "\n",
       "       lag2_ta_min_six_pm2  lag2_ta_max_six_pm2  lag2_ta_mean_six_pm2  \\\n",
       "0                       14                   21                    17   \n",
       "1                       15                   22                    18   \n",
       "2                       18                   24                    20   \n",
       "3                       12                   21                    16   \n",
       "4                       19                   24                    21   \n",
       "...                    ...                  ...                   ...   \n",
       "25971                   23                   26                    24   \n",
       "25972                   20                   24                    21   \n",
       "25973                   20                   25                    22   \n",
       "25974                   21                   26                    23   \n",
       "25975                   20                   22                    21   \n",
       "\n",
       "       lag2_min_ws  lag2_max_ws  lag2_mean_ws  \n",
       "0              0.3          3.5           1.7  \n",
       "1              0.0          3.7           1.6  \n",
       "2              0.1          3.7           1.9  \n",
       "3              0.1          4.1           1.6  \n",
       "4              0.4          4.7           2.3  \n",
       "...            ...          ...           ...  \n",
       "25971          0.7          3.5           2.5  \n",
       "25972          0.0          1.5           0.7  \n",
       "25973          1.1          3.8           2.2  \n",
       "25974          0.0          2.9           1.4  \n",
       "25975          0.0          3.8           2.1  \n",
       "\n",
       "[25976 rows x 63 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.concat()pd.DataFrame([sido_en, data.jenks_cluster])\n",
    "new_data = pd.concat(\n",
    "    [\n",
    "        sido_en, data.min_tafeel, data.max_tafeel, data.mean_tafeel, data.gap_tafeel,\n",
    "        data.ta_min_six_am1, data.ta_max_six_am1, data.ta_mean_six_am1, data.ta_min_six_am2, data.ta_max_six_am2, data.ta_mean_six_am2,\n",
    "        data.ta_min_six_pm1, data.ta_max_six_pm1, data.ta_mean_six_pm1, data.ta_min_six_pm2, data.ta_max_six_pm2, data.ta_mean_six_pm2,\n",
    "        data.min_ws, data.max_ws, data.mean_ws,\n",
    "        data.jenks_cluster,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "new_data = new_data[34:].reset_index(drop=True)\n",
    "new_data = pd.concat([new_data, lag_data_1], axis=1)\n",
    "new_data = pd.concat([new_data, lag_data_2], axis=1)\n",
    "print(new_data.shape)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_data.drop(columns=[\"jenks_cluster\"])\n",
    "y = new_data.jenks_cluster\n",
    "\n",
    "seed_num = 43\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=seed_num)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.1, stratify=y_temp, random_state=seed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18702, 62), (2078, 62), (5196, 62))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18702,), (2078,), (5196,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'verbosity': 0,\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        # 'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),\n",
    "        'eval_stopping_rounds': 10,\n",
    "        'tree_method': 'gpu_hist',\n",
    "    }\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed_num)\n",
    "    accuracy_scores = []\n",
    "    \n",
    "    for train_idx, valid_idx in skf.split(X_train, y_train):\n",
    "        X_train_fold, X_valid_fold = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "        y_train_fold, y_valid_fold = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "    \n",
    "        model = XGBClassifier(**param)\n",
    "        model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            eval_set=[(X_valid_fold, y_valid_fold)],\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        y_pred = model.predict(X_valid_fold)\n",
    "        accuracy = accuracy_score(y_valid_fold, y_pred)\n",
    "        accuracy_scores.append(accuracy)\n",
    "    \n",
    "    return np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-24 16:48:32,931] A new study created in memory with name: no-name-dd242377-15f5-476d-bcef-0010419a966c\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:50:13,326] Trial 0 finished with value: 0.8480379434707469 and parameters: {'n_estimators': 866, 'max_depth': 10, 'learning_rate': 0.016981173397840506}. Best is trial 0 with value: 0.8480379434707469.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:51:04,373] Trial 1 finished with value: 0.8486261644703081 and parameters: {'n_estimators': 717, 'max_depth': 8, 'learning_rate': 0.02394662128669831}. Best is trial 1 with value: 0.8486261644703081.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:51:23,346] Trial 2 finished with value: 0.8468613585260597 and parameters: {'n_estimators': 129, 'max_depth': 10, 'learning_rate': 0.03747517884300082}. Best is trial 1 with value: 0.8486261644703081.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:51:31,412] Trial 3 finished with value: 0.8504437602116738 and parameters: {'n_estimators': 220, 'max_depth': 5, 'learning_rate': 0.04724611647786544}. Best is trial 3 with value: 0.8504437602116738.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:52:00,674] Trial 4 finished with value: 0.8486260072301868 and parameters: {'n_estimators': 341, 'max_depth': 8, 'learning_rate': 0.012161211318009348}. Best is trial 3 with value: 0.8504437602116738.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:52:10,277] Trial 5 finished with value: 0.8481445093893795 and parameters: {'n_estimators': 399, 'max_depth': 3, 'learning_rate': 0.026657501260519016}. Best is trial 3 with value: 0.8504437602116738.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:53:08,169] Trial 6 finished with value: 0.8463267278187795 and parameters: {'n_estimators': 460, 'max_depth': 9, 'learning_rate': 0.0040496126278971745}. Best is trial 3 with value: 0.8504437602116738.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:53:52,165] Trial 7 finished with value: 0.8470219435736677 and parameters: {'n_estimators': 487, 'max_depth': 8, 'learning_rate': 0.005372819812185502}. Best is trial 3 with value: 0.8504437602116738.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:55:47,931] Trial 8 finished with value: 0.8462732518829504 and parameters: {'n_estimators': 917, 'max_depth': 9, 'learning_rate': 0.0020065777881681296}. Best is trial 3 with value: 0.8504437602116738.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:56:41,111] Trial 9 finished with value: 0.8490003530755453 and parameters: {'n_estimators': 714, 'max_depth': 8, 'learning_rate': 0.010980153597899667}. Best is trial 3 with value: 0.8504437602116738.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:56:45,883] Trial 10 finished with value: 0.8491604521082328 and parameters: {'n_estimators': 160, 'max_depth': 4, 'learning_rate': 0.09324998709012951}. Best is trial 3 with value: 0.8504437602116738.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:56:49,682] Trial 11 finished with value: 0.8500159670195993 and parameters: {'n_estimators': 125, 'max_depth': 4, 'learning_rate': 0.09546375322522947}. Best is trial 3 with value: 0.8504437602116738.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:56:58,680] Trial 12 finished with value: 0.8500159098413732 and parameters: {'n_estimators': 254, 'max_depth': 5, 'learning_rate': 0.09574450636605807}. Best is trial 3 with value: 0.8504437602116738.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:57:10,019] Trial 13 finished with value: 0.8498022634000746 and parameters: {'n_estimators': 258, 'max_depth': 6, 'learning_rate': 0.050187018336910694}. Best is trial 3 with value: 0.8504437602116738.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:57:15,111] Trial 14 finished with value: 0.8516200163815617 and parameters: {'n_estimators': 133, 'max_depth': 5, 'learning_rate': 0.051910828060418926}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:57:42,028] Trial 15 finished with value: 0.8484120463086452 and parameters: {'n_estimators': 614, 'max_depth': 6, 'learning_rate': 0.054367224107007}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:57:53,088] Trial 16 finished with value: 0.8480376289905042 and parameters: {'n_estimators': 293, 'max_depth': 5, 'learning_rate': 0.005917887649163031}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:57:57,647] Trial 17 finished with value: 0.8457918398094822 and parameters: {'n_estimators': 185, 'max_depth': 3, 'learning_rate': 0.03325433122040834}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:58:17,833] Trial 18 finished with value: 0.8495882595948638 and parameters: {'n_estimators': 586, 'max_depth': 5, 'learning_rate': 0.051426281272838534}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:58:40,016] Trial 19 finished with value: 0.8514063985293759 and parameters: {'n_estimators': 388, 'max_depth': 7, 'learning_rate': 0.020115215559817597}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:59:01,897] Trial 20 finished with value: 0.8505509836799048 and parameters: {'n_estimators': 379, 'max_depth': 7, 'learning_rate': 0.018136479283834484}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:59:24,255] Trial 21 finished with value: 0.8507648016558814 and parameters: {'n_estimators': 385, 'max_depth': 7, 'learning_rate': 0.01730140814849528}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 16:59:55,747] Trial 22 finished with value: 0.8494813506068754 and parameters: {'n_estimators': 499, 'max_depth': 7, 'learning_rate': 0.007815167709164092}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:00:14,915] Trial 23 finished with value: 0.8503903557486273 and parameters: {'n_estimators': 426, 'max_depth': 6, 'learning_rate': 0.016117963968449132}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:00:34,374] Trial 24 finished with value: 0.8511925519642866 and parameters: {'n_estimators': 342, 'max_depth': 7, 'learning_rate': 0.02667389087084418}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:00:48,705] Trial 25 finished with value: 0.8504973790930676 and parameters: {'n_estimators': 312, 'max_depth': 6, 'learning_rate': 0.02553210724086721}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:01:24,541] Trial 26 finished with value: 0.8454712700856387 and parameters: {'n_estimators': 545, 'max_depth': 7, 'learning_rate': 0.0013570423027022569}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:01:30,625] Trial 27 finished with value: 0.8493208227374934 and parameters: {'n_estimators': 206, 'max_depth': 4, 'learning_rate': 0.066937212769357}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:01:43,223] Trial 28 finished with value: 0.8470218292172158 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.029167299973460636}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:02:14,372] Trial 29 finished with value: 0.8499092295662889 and parameters: {'n_estimators': 703, 'max_depth': 6, 'learning_rate': 0.013674961662554006}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:02:33,113] Trial 30 finished with value: 0.8492677184601332 and parameters: {'n_estimators': 286, 'max_depth': 7, 'learning_rate': 0.009023711911829786}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:02:54,226] Trial 31 finished with value: 0.8508182347080409 and parameters: {'n_estimators': 360, 'max_depth': 7, 'learning_rate': 0.01742854679311125}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:03:19,926] Trial 32 finished with value: 0.8491072334744206 and parameters: {'n_estimators': 341, 'max_depth': 8, 'learning_rate': 0.020521497886755665}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:04:06,467] Trial 33 finished with value: 0.8481448381641787 and parameters: {'n_estimators': 847, 'max_depth': 7, 'learning_rate': 0.039044500709365354}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:04:38,283] Trial 34 finished with value: 0.8495349837828258 and parameters: {'n_estimators': 438, 'max_depth': 8, 'learning_rate': 0.02163625825080373}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:04:47,108] Trial 35 finished with value: 0.850817977406024 and parameters: {'n_estimators': 246, 'max_depth': 5, 'learning_rate': 0.06861614495411639}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:05:36,861] Trial 36 finished with value: 0.8479307628861852 and parameters: {'n_estimators': 341, 'max_depth': 10, 'learning_rate': 0.01370590183216599}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:06:00,148] Trial 37 finished with value: 0.8504976078059714 and parameters: {'n_estimators': 527, 'max_depth': 6, 'learning_rate': 0.04042438574567486}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:06:32,672] Trial 38 finished with value: 0.8471821712573636 and parameters: {'n_estimators': 365, 'max_depth': 9, 'learning_rate': 0.03125159531996645}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:07:17,332] Trial 39 finished with value: 0.8485726313562534 and parameters: {'n_estimators': 652, 'max_depth': 8, 'learning_rate': 0.023397630472131788}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:07:42,665] Trial 40 finished with value: 0.8483586418455988 and parameters: {'n_estimators': 465, 'max_depth': 7, 'learning_rate': 0.06998146079129174}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:07:48,380] Trial 41 finished with value: 0.8511923375459391 and parameters: {'n_estimators': 155, 'max_depth': 5, 'learning_rate': 0.0660915945101913}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:07:55,500] Trial 42 finished with value: 0.8511388616101103 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.0408540595978733}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:08:00,324] Trial 43 finished with value: 0.8499089436751591 and parameters: {'n_estimators': 159, 'max_depth': 4, 'learning_rate': 0.04477504987500289}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:08:06,377] Trial 44 finished with value: 0.850604173724604 and parameters: {'n_estimators': 164, 'max_depth': 5, 'learning_rate': 0.06689594383955057}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:08:14,330] Trial 45 finished with value: 0.8514596886359707 and parameters: {'n_estimators': 220, 'max_depth': 5, 'learning_rate': 0.035138825829835664}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:08:17,494] Trial 46 finished with value: 0.847449322223604 and parameters: {'n_estimators': 123, 'max_depth': 3, 'learning_rate': 0.060092340696036806}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:08:24,301] Trial 47 finished with value: 0.8501228760075875 and parameters: {'n_estimators': 231, 'max_depth': 4, 'learning_rate': 0.03555781198918536}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:08:36,751] Trial 48 finished with value: 0.8504438888626822 and parameters: {'n_estimators': 273, 'max_depth': 6, 'learning_rate': 0.02667257653678616}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:08:41,849] Trial 49 finished with value: 0.8508180631733631 and parameters: {'n_estimators': 137, 'max_depth': 5, 'learning_rate': 0.07850486360414795}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:08:51,587] Trial 50 finished with value: 0.8492141710515219 and parameters: {'n_estimators': 219, 'max_depth': 6, 'learning_rate': 0.08113761744620028}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:08:58,934] Trial 51 finished with value: 0.8516199734978922 and parameters: {'n_estimators': 201, 'max_depth': 5, 'learning_rate': 0.04222687770730944}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:09:08,055] Trial 52 finished with value: 0.8499089007914897 and parameters: {'n_estimators': 317, 'max_depth': 4, 'learning_rate': 0.05274107778857346}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:09:14,685] Trial 53 finished with value: 0.8509784195080672 and parameters: {'n_estimators': 178, 'max_depth': 5, 'learning_rate': 0.03286899724184448}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:09:22,709] Trial 54 finished with value: 0.8496952257610779 and parameters: {'n_estimators': 223, 'max_depth': 5, 'learning_rate': 0.047076133243887625}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:09:27,865] Trial 55 finished with value: 0.8439206108921662 and parameters: {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.0032745846445900255}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:09:36,762] Trial 56 finished with value: 0.8515666548021847 and parameters: {'n_estimators': 253, 'max_depth': 5, 'learning_rate': 0.05531108550841587}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:09:45,676] Trial 57 finished with value: 0.850176366237973 and parameters: {'n_estimators': 306, 'max_depth': 4, 'learning_rate': 0.02694198474823915}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:09:55,456] Trial 58 finished with value: 0.8498555820957823 and parameters: {'n_estimators': 416, 'max_depth': 3, 'learning_rate': 0.044739495303395785}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:10:06,840] Trial 59 finished with value: 0.8497486731077938 and parameters: {'n_estimators': 259, 'max_depth': 6, 'learning_rate': 0.055789626152614596}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:10:12,732] Trial 60 finished with value: 0.8501762947651905 and parameters: {'n_estimators': 197, 'max_depth': 4, 'learning_rate': 0.03597522367919397}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:10:18,380] Trial 61 finished with value: 0.8499090723261675 and parameters: {'n_estimators': 154, 'max_depth': 5, 'learning_rate': 0.084428666955308}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:10:27,172] Trial 62 finished with value: 0.8504972075583896 and parameters: {'n_estimators': 247, 'max_depth': 5, 'learning_rate': 0.0572725444500687}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:10:37,230] Trial 63 finished with value: 0.850657592482207 and parameters: {'n_estimators': 281, 'max_depth': 5, 'learning_rate': 0.030301009730456078}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:10:42,803] Trial 64 finished with value: 0.8496418784762574 and parameters: {'n_estimators': 121, 'max_depth': 6, 'learning_rate': 0.09633793584672931}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:10:48,322] Trial 65 finished with value: 0.8501229617749265 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.045456556554532686}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:10:56,387] Trial 66 finished with value: 0.8493743415569917 and parameters: {'n_estimators': 216, 'max_depth': 5, 'learning_rate': 0.02055058970827642}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:11:14,245] Trial 67 finished with value: 0.8491607951775884 and parameters: {'n_estimators': 326, 'max_depth': 7, 'learning_rate': 0.06100418609703431}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:11:21,537] Trial 68 finished with value: 0.8484122035487666 and parameters: {'n_estimators': 146, 'max_depth': 6, 'learning_rate': 0.014650804008415702}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:12:05,754] Trial 69 finished with value: 0.8475569888230863 and parameters: {'n_estimators': 813, 'max_depth': 7, 'learning_rate': 0.03743483843951159}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:12:25,638] Trial 70 finished with value: 0.8491607665884754 and parameters: {'n_estimators': 287, 'max_depth': 8, 'learning_rate': 0.05127480604611555}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:12:32,602] Trial 71 finished with value: 0.8509250150450207 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.04297569234602527}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:12:41,307] Trial 72 finished with value: 0.8510318811493395 and parameters: {'n_estimators': 235, 'max_depth': 5, 'learning_rate': 0.023786106444979055}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:12:54,899] Trial 73 finished with value: 0.8504973505039546 and parameters: {'n_estimators': 390, 'max_depth': 5, 'learning_rate': 0.038233833921557964}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:13:21,434] Trial 74 finished with value: 0.8498021204545096 and parameters: {'n_estimators': 948, 'max_depth': 4, 'learning_rate': 0.011295834724489787}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:13:28,846] Trial 75 finished with value: 0.8511923232513826 and parameters: {'n_estimators': 201, 'max_depth': 5, 'learning_rate': 0.030120645462621536}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:13:41,082] Trial 76 finished with value: 0.8503369226964679 and parameters: {'n_estimators': 266, 'max_depth': 6, 'learning_rate': 0.029384200870112107}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:13:47,787] Trial 77 finished with value: 0.8486791972748857 and parameters: {'n_estimators': 175, 'max_depth': 5, 'learning_rate': 0.018818584845094175}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:14:03,498] Trial 78 finished with value: 0.8503903557486273 and parameters: {'n_estimators': 355, 'max_depth': 6, 'learning_rate': 0.03222648662022546}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:14:07,397] Trial 79 finished with value: 0.8493208227374934 and parameters: {'n_estimators': 127, 'max_depth': 4, 'learning_rate': 0.0751460309866208}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:14:14,434] Trial 80 finished with value: 0.8490538718950438 and parameters: {'n_estimators': 104, 'max_depth': 7, 'learning_rate': 0.024553373558750473}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:14:21,857] Trial 81 finished with value: 0.8509784909808497 and parameters: {'n_estimators': 204, 'max_depth': 5, 'learning_rate': 0.041657600533850016}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:14:27,633] Trial 82 finished with value: 0.8501764805944247 and parameters: {'n_estimators': 156, 'max_depth': 5, 'learning_rate': 0.06499878148465817}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:14:36,078] Trial 83 finished with value: 0.8504438316844564 and parameters: {'n_estimators': 236, 'max_depth': 5, 'learning_rate': 0.04917232262669847}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:14:43,655] Trial 84 finished with value: 0.8512457705980985 and parameters: {'n_estimators': 205, 'max_depth': 5, 'learning_rate': 0.029077491921307104}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:14:57,683] Trial 85 finished with value: 0.8499092152717325 and parameters: {'n_estimators': 310, 'max_depth': 6, 'learning_rate': 0.028297256790771785}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:15:03,931] Trial 86 finished with value: 0.8473424990029546 and parameters: {'n_estimators': 207, 'max_depth': 4, 'learning_rate': 0.021773504836172932}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:15:10,313] Trial 87 finished with value: 0.8502832466368482 and parameters: {'n_estimators': 171, 'max_depth': 5, 'learning_rate': 0.032519753836662155}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:15:19,814] Trial 88 finished with value: 0.8488396822605984 and parameters: {'n_estimators': 253, 'max_depth': 5, 'learning_rate': 0.00913898344960086}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:15:32,826] Trial 89 finished with value: 0.8472357329605312 and parameters: {'n_estimators': 145, 'max_depth': 8, 'learning_rate': 0.019416123080169104}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:15:54,568] Trial 90 finished with value: 0.8500695144282104 and parameters: {'n_estimators': 504, 'max_depth': 6, 'learning_rate': 0.025509216742668112}. Best is trial 14 with value: 0.8516200163815617.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:16:01,850] Trial 91 finished with value: 0.8516201021489007 and parameters: {'n_estimators': 199, 'max_depth': 5, 'learning_rate': 0.03552389404617955}. Best is trial 91 with value: 0.8516201021489007.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:16:09,588] Trial 92 finished with value: 0.8511922803677132 and parameters: {'n_estimators': 213, 'max_depth': 5, 'learning_rate': 0.03615850056399683}. Best is trial 91 with value: 0.8516201021489007.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:16:20,837] Trial 93 finished with value: 0.8480911192208895 and parameters: {'n_estimators': 297, 'max_depth': 5, 'learning_rate': 0.0063164788415457}. Best is trial 91 with value: 0.8516201021489007.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:16:30,291] Trial 94 finished with value: 0.8498556106848951 and parameters: {'n_estimators': 268, 'max_depth': 5, 'learning_rate': 0.0490522814094402}. Best is trial 91 with value: 0.8516201021489007.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:16:35,496] Trial 95 finished with value: 0.8490535002365748 and parameters: {'n_estimators': 171, 'max_depth': 4, 'learning_rate': 0.03344161332630889}. Best is trial 91 with value: 0.8516201021489007.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:16:44,380] Trial 96 finished with value: 0.8491604521082327 and parameters: {'n_estimators': 239, 'max_depth': 5, 'learning_rate': 0.01631616188209125}. Best is trial 91 with value: 0.8516201021489007.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:17:02,380] Trial 97 finished with value: 0.8484121606650972 and parameters: {'n_estimators': 330, 'max_depth': 7, 'learning_rate': 0.05691494897863539}. Best is trial 91 with value: 0.8516201021489007.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:17:22,116] Trial 98 finished with value: 0.8498023205783006 and parameters: {'n_estimators': 455, 'max_depth': 6, 'learning_rate': 0.0401545381201739}. Best is trial 91 with value: 0.8516201021489007.\n",
      "C:\\Users\\Eco\\AppData\\Local\\Temp\\ipykernel_14984\\1761258887.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
      "[I 2024-09-24 17:17:42,231] Trial 99 finished with value: 0.8508178630495721 and parameters: {'n_estimators': 583, 'max_depth': 5, 'learning_rate': 0.028057366810454922}. Best is trial 91 with value: 0.8516201021489007.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 0.8516201021489007\n",
      "Best parameters: {'n_estimators': 199, 'max_depth': 5, 'learning_rate': 0.03552389404617955}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(f\"Best trial: {study.best_trial.value}\")\n",
    "print(f\"Best parameters: {study.best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 최적의 모델로 최종 테스트 데이터 성능 평가\n",
    "best_model = XGBClassifier(**study.best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "preds = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix # 혼동행렬\n",
    "from sklearn.metrics import accuracy_score # 정확도\n",
    "from sklearn.metrics import precision_score # 정밀도\n",
    "from sklearn.metrics import recall_score # 재현율\n",
    "from sklearn.metrics import f1_score # f1 스코어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_class_score(y_test, preds, type_average=\"macro\"):\n",
    "    mask_class_0 = y_test == 0\n",
    "    mask_class_1 = y_test == 1\n",
    "    mask_class_2 = y_test == 2\n",
    "    \n",
    "    results = pd.DataFrame(\n",
    "        {\n",
    "            \"class0\": cal_matrix(y_test[mask_class_0], preds[mask_class_0], type_average),\n",
    "            \"class1\": cal_matrix(y_test[mask_class_1], preds[mask_class_1], type_average),\n",
    "            \"class2\": cal_matrix(y_test[mask_class_2], preds[mask_class_2], type_average),\n",
    "        }\n",
    "    )\n",
    "    results = results.T\n",
    "    results.columns = [\"accuracy\", \"precision\", \"recall\", \"F1\"]\n",
    "    return results\n",
    "\n",
    "def cal_matrix(y_test, preds, type_average):\n",
    "    result_class = []\n",
    "    result_class.append(accuracy_score(y_test, preds))\n",
    "    result_class.append(precision_score(y_test, preds, average=type_average).tolist())\n",
    "    result_class.append(recall_score(y_test, preds, average=type_average).tolist())\n",
    "    result_class.append(f1_score(y_test, preds, average=type_average).tolist())\n",
    "    return result_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dev_folder\\온열환자_과제_20240923_Q\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Dev_folder\\온열환자_과제_20240923_Q\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Dev_folder\\온열환자_과제_20240923_Q\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "test = cal_class_score(y_test, preds, type_average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class0</th>\n",
       "      <td>0.945838</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.472919</td>\n",
       "      <td>0.486082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class1</th>\n",
       "      <td>0.593863</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.197954</td>\n",
       "      <td>0.248396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class2</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision    recall        F1\n",
       "class0  0.945838   0.500000  0.472919  0.486082\n",
       "class1  0.593863   0.333333  0.197954  0.248396\n",
       "class2  0.400000   0.333333  0.133333  0.190476"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.895     0.946     0.920      3988\n",
      "           1      0.706     0.594     0.645      1108\n",
      "           2      0.816     0.400     0.537       100\n",
      "\n",
      "    accuracy                          0.860      5196\n",
      "   macro avg      0.806     0.647     0.701      5196\n",
      "weighted avg      0.853     0.860     0.854      5196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
